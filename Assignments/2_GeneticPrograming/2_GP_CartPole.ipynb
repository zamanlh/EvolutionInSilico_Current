{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP Homework: Balancing a pole on cart. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "In this homework notebook, the goal is to evolve a genetic program that controls a cart with a pole attached to it by a passive joint. The pole is initially positioned at a random angle and with a random initial velocity (within some reasonable range). \n",
    "\n",
    "You can move the cart to the left or to the right with the same amount of force. This is represented, and transmitted as an action, in the simulation as a 0 (move left) or 1 (move right). In control systems lingo, this is called bang-bang control. Your goal is to balance the pole without letting it tilt too far in either direction by only moving the cart. \n",
    "\n",
    "The simulation of the cart will give you 4 bits of information in each step, the cart's position, the cart's velocity, the pole's angle, and the pole's velocity measured at it's highest point. You should probably create terminal nodes that take advantage of these in your evolved programs. \n",
    "\n",
    "### The Simulation\n",
    "To get a physical simulation of the cart-pole problem and some nice visuals, we'll use the OpenAI Gym package. I'll walk through some of the details of this package here, but first we'll have to install it. The easiest way is to install it via `pip install gym` in the command line, but luckily Jupyter Notebooks provides a little trick to do this for us. If this comes back with an error, let me know and we'll try to get it resolved!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Downloading pygame-2.1.2-cp38-cp38-macosx_10_9_x86_64.whl (8.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.9 MB 13.6 MB/s eta 0:00:01     |█████████████████▊              | 4.9 MB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pygame\n",
      "Successfully installed pygame-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /Users/zamanlh/opt/anaconda3/lib/python3.8/site-packages (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/zamanlh/opt/anaconda3/lib/python3.8/site-packages (from gym) (1.19.2)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/zamanlh/opt/anaconda3/lib/python3.8/site-packages (from gym) (0.0.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0; python_version < \"3.10\" in /Users/zamanlh/opt/anaconda3/lib/python3.8/site-packages (from gym) (4.11.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/zamanlh/opt/anaconda3/lib/python3.8/site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/zamanlh/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.10.0; python_version < \"3.10\"->gym) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's play with the simulation environment!\n",
    "This code will create the Cart-Pole environment and simulate it for 500 steps where each action is sampled randomly from the set of possible actions (`possible_actions`).\n",
    "\n",
    "We'll also save the output of this simulation to a new folder \"cartpole-results\". This will save a detailed trace of each action, but also a little video of the cart and pole! If you turn this line off, the simulation will run without graphics and be **MUCH** faster (*hint: don't do this during evolution, but only when you want to inspect a particular evolved solution)*.\n",
    "\n",
    "Note the 4 returns from the `env.step(action)` call. The four values I described in the Goals section are actually all within the first return, `observation`. We'll look a bit more into that in a second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gym.wrappers' has no attribute 'Monitor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5cb531b65e3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#This is the bit that turns on the \"recording\" of the run. Slow, but cool.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./cartpole-results\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#Push cart left, or push it right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gym.wrappers' has no attribute 'Monitor'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import random\n",
    "\n",
    "#Setup the cart pole balancing problem\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "#This tells the environment to run for a max of 500 steps\n",
    "#Less than 200 is probably too short, and more than 500 might\n",
    "#be overkill, but I'm not really sure!\n",
    "env._max_episode_steps = 500\n",
    "\n",
    "#This is the bit that turns on the \"recording\" of the run. Slow, but cool.\n",
    "env = gym.wrappers.Monitor(env, \"./cartpole-results\", force=True)\n",
    "\n",
    "#Push cart left, or push it right\n",
    "possible_actions = [0,1]\n",
    "\n",
    "#Reset the cart and pole with a random initial condition\n",
    "#We can get all the info about the car and the pole from the\n",
    "#observation variable and do something with it. But for now\n",
    "#we'll just ignore it. \n",
    "observation = env.reset()\n",
    "\n",
    "for i in range(500):\n",
    "    #Pick a random action, and perform a step in the simulation\n",
    "    action = random.choice(possible_actions)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    \n",
    "    #The simulation may tell us it's over before we've run all 500 steps\n",
    "    #This often happens when the pole tilts too far!\n",
    "    if done: \n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we go look at that video, let's look into some of these variables.\n",
    "`observation, reward, done, info = env.step(action)`\n",
    "In case you haven't seen this notation before, it's just a quick way of unpacking multiple return values from a python function. In this case, most of the useful bits are wrapped up in `observation`. \n",
    "\n",
    "In this environment, `reward` returns 1 for each step, regardless of if that step was useful or not. Similarly, `info` is probably always empty, and `done` is 0 until the pole has tipped too far. These variables are more useful in other Gym environments and this package provides a consistent interface to simulation environments to make it easy to plug-and-play. \n",
    "\n",
    "### Let's look at what is in the last observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03204726 -0.2481107   0.22197433  1.1391095 ]\n"
     ]
    }
   ],
   "source": [
    "print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The documentation for this environment tells us what these values represent:\n",
    "\n",
    "### Observation\n",
    "Num | Observation | Min | Max\n",
    "---|---|---|---\n",
    "0 | Cart Position | -2.4 | 2.4\n",
    "1 | Cart Velocity | -Inf | Inf\n",
    "2 | Pole Angle | ~ -41.8&deg; | ~ 41.8&deg;\n",
    "3 | Pole Velocity At Tip | -Inf | Inf\n",
    "\n",
    "### Remember, these are probably the most useful values to use as variables in your genetic program!\n",
    "\n",
    "### Now onto the video!\n",
    "The code block below will load the video file saved in the subdirectory we specified, and render it in the browser. Don't worry too much what exactly is going on here. If you can't get it to load, you can always look in the subfolder and play the video from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CartPoleEnv' object has no attribute 'file_infix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8eb5ef312b27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./cartpole-results/openaigym.video.%s.video000000.mp4'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_infix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r+b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m HTML(data='''\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gym/core.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"attempted to get missing private attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gym/core.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"attempted to get missing private attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CartPoleEnv' object has no attribute 'file_infix'"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "video = io.open('./cartpole-results/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    ".format(encoded.decode('ascii')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cool!\n",
    "Note that the simulation ended as the pole leaned too far. This saves execution time, especially when we're evaluating random programs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the code you've seen before in the GP worksheets. \n",
    "You shouldn't need to change any of this, but you might want to implement smarter mutation functions. That part of the code begins at Line 164."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import random\n",
    "\n",
    "class GPNode:\n",
    "    def __init__(self, node_type=None):\n",
    "        self.parent = None\n",
    "        self.node_type = node_type\n",
    "        self.children = []\n",
    "        self.depth = 0\n",
    "        \n",
    "    def add_child(self, child_node):\n",
    "        child_node.depth = self.depth+1\n",
    "        self.children.append(child_node)\n",
    "        child_node.parent = self\n",
    "    \n",
    "    \n",
    "class GPConstNode(GPNode):\n",
    "    def __init__(self, value=None):\n",
    "        super().__init__(node_type=\"Const\")\n",
    "        self.const_value = value\n",
    "    \n",
    "    def evaluate(self, input_state):\n",
    "        return self.const_value\n",
    "        \n",
    "    def pretty_print(self, indents=0):\n",
    "        print('  '*indents + str(self.const_value) \n",
    "              + ' : ' + str(self.depth))\n",
    "        \n",
    "    def deepcopy(self):\n",
    "        new_node = GPConstNode(value=self.const_value)\n",
    "        new_node.depth = self.depth;\n",
    "        return new_node\n",
    "        \n",
    "        \n",
    "class GPVariableNode(GPNode):\n",
    "    def __init__(self, variable_name=None):\n",
    "        super().__init__(node_type=\"Variable\")\n",
    "        self.variable_name = variable_name\n",
    "    \n",
    "    def evaluate(self, input_state):\n",
    "        return input_state[self.variable_name]\n",
    "    \n",
    "    def pretty_print(self, indents=0):\n",
    "        print('  '*indents + str(self.variable_name)\n",
    "              + ' : ' + str(self.depth))\n",
    "        \n",
    "    def deepcopy(self):\n",
    "        new_node = GPVariableNode(variable_name = self.variable_name)\n",
    "        new_node.depth = self.depth\n",
    "        return new_node\n",
    "        \n",
    "class GPFunctionNode(GPNode):\n",
    "    def __init__(self, arg_count, func_name=None, gp_function=None):\n",
    "        super().__init__(node_type=\"Function\")\n",
    "        self.argument_count = arg_count\n",
    "        self.gp_function = gp_function\n",
    "        self.function_name = func_name\n",
    "        \n",
    "    def evaluate(self, input_state): \n",
    "        assert self.argument_count == len(self.children), \\\n",
    "        'Number of child nodes must match argument count'\n",
    "\n",
    "        child_results = [c.evaluate(input_state) for c in self.children]\n",
    "        return self.gp_function(*child_results)\n",
    "\n",
    "    def pretty_print(self, indents=0):\n",
    "        print('  '*indents + str(self.function_name) \n",
    "              + ' : ' + str(self.depth))\n",
    "        \n",
    "        for child in self.children:\n",
    "            child.pretty_print(indents+1)\n",
    "        \n",
    "    def deepcopy(self):\n",
    "        new_node = GPFunctionNode(self.argument_count, \n",
    "                                   self.function_name, \n",
    "                                   self.gp_function)\n",
    "        new_node.depth = self.depth\n",
    "        \n",
    "        for child in self.children:\n",
    "            new_node.add_child(child.deepcopy())\n",
    "        \n",
    "        return new_node\n",
    "class GPIndividual:\n",
    "    # This is the beef of the individual code. We're growing random \n",
    "    # trees with a bit of extra sauce. \n",
    "    # We've defined a prob_terminal value that determines how \n",
    "    # likely it is that we select a terminal when choosing a random GP node. \n",
    "    # We're also limiting the depth of the trees we grow, because this is \n",
    "    # Python after all. \n",
    "    def grow_random(self, cur_node=None, cur_depth=0):\n",
    "        if (random.random() < self.prob_terminal \n",
    "            or cur_depth == self.max_genotype_depth-1):\n",
    "            new_node = random.choice(self.terminal_set).deepcopy()\n",
    "            new_node.parent = cur_node\n",
    "            new_node.depth = cur_depth\n",
    "        else:\n",
    "            new_node = random.choice(self.function_set).deepcopy()\n",
    "            new_node.depth = cur_depth\n",
    "            new_node.parent = cur_node\n",
    "            for i in range(new_node.argument_count):\n",
    "                new_node.add_child(self.grow_random(cur_node=new_node, \n",
    "                                                    cur_depth=cur_depth+1))\n",
    "        return new_node\n",
    "    \n",
    "    \n",
    "    # prob_terminal and max_depth have default parameters but you \n",
    "    # can use them to control how big the trees can get and how\n",
    "    # likely you are to pick function/terminal nodes when growing\n",
    "    # and mutating trees. \n",
    "    def __init__(self, function_set, terminal_set, \n",
    "                 prob_terminal=0.2, max_depth=5):\n",
    "        self.max_genotype_depth = max_depth\n",
    "        self.fitness = None\n",
    "        self.function_set = function_set\n",
    "        self.terminal_set = terminal_set\n",
    "        self.prob_terminal = prob_terminal\n",
    "        \n",
    "        self.genotype = self.grow_random()\n",
    "        \n",
    "        \n",
    "    def pretty_print(self):\n",
    "        self.genotype.pretty_print()\n",
    "        \n",
    "        \n",
    "    def deepcopy(self):\n",
    "        new_individual = GPIndividual(self.function_set, \n",
    "                                      self.terminal_set, \n",
    "                                      self.prob_terminal, \n",
    "                                      self.max_genotype_depth)\n",
    "        new_individual.genotype = self.genotype.deepcopy()\n",
    "        return new_individual\n",
    "    \n",
    "    \n",
    "    # This function just visits each node in the genome, growing\n",
    "    # the list of nodes as it encounters children.\n",
    "    def visit_genotype_nodes(self, cur_node=None):\n",
    "        if cur_node == None: \n",
    "            cur_node = self.genotype\n",
    "            \n",
    "        node_list = [cur_node]\n",
    "        visitor_index = 0\n",
    "        \n",
    "        while visitor_index < len(node_list):\n",
    "            if len(node_list[visitor_index].children) > 0:\n",
    "                node_list.extend(node_list[visitor_index].children)\n",
    "            visitor_index += 1\n",
    "            \n",
    "        return node_list\n",
    "        \n",
    "    \n",
    "    def evaluate(self, input_state):\n",
    "        #evaluate the genotype\n",
    "        individual_output = self.genotype.evaluate(input_state)\n",
    "        if individual_output < 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    \n",
    "    #TODO: You might want to implement a more clever mutation function!\n",
    "    def mutate(self):\n",
    "        # get a list of nodes...\n",
    "        genotype_nodes = self.visit_genotype_nodes()\n",
    "        # and pick one! \n",
    "        random_node = random.choice(genotype_nodes)\n",
    "        \n",
    "        if random_node.parent == None:\n",
    "            #We've picked the root, so just grow a whole new genotype\n",
    "            self.genotype = self.grow_random()\n",
    "        else:\n",
    "            #generate a new subtree using the random node's parent\n",
    "            #as the parent for this subtree\n",
    "            new_node = self.grow_random(random_node.parent, random_node.depth)\n",
    "            #remove old node, add new node to parent's list of children\n",
    "            random_node.parent.children.remove(random_node)\n",
    "            random_node.parent.add_child(new_node)\n",
    "\n",
    "            \n",
    "class GPPopulation:\n",
    "    def __init__(self, pop_size, function_set, terminal_set, max_depth, prob_terminal):\n",
    "        self.pop_size = pop_size\n",
    "        self.terminal_set = terminal_set\n",
    "        self.function_set = function_set\n",
    "        self.max_depth = max_depth\n",
    "        self.prob_terminal = prob_terminal\n",
    "        \n",
    "        self.population = [GPIndividual(self.function_set, \n",
    "                                        self.terminal_set,\n",
    "                                        self.prob_terminal, \n",
    "                                        self.max_depth) \n",
    "                           for _ in range(self.pop_size)]\n",
    "        \n",
    "        \n",
    "    def update_fitnesses(self, fitness_function):\n",
    "        fitnesses = []\n",
    "        for individual in self.population:\n",
    "            individual.fitness = fitness_function(individual)\n",
    "            fitnesses.append(individual.fitness)\n",
    "            \n",
    "        return fitnesses\n",
    "    \n",
    "    \n",
    "    def do_timestep(self, fitness_function, selection_function, mutation_prob):\n",
    "        fitness_list = self.update_fitnesses(fitness_function)\n",
    "        selected_individuals = [selection_function(self.population) \n",
    "                                for _ in range(self.pop_size)]\n",
    "        \n",
    "        for individual_idx in range(len(selected_individuals)):\n",
    "            individual = selected_individuals[individual_idx].deepcopy()\n",
    "            \n",
    "            if random.random() < mutation_prob:\n",
    "                individual.mutate()\n",
    "            \n",
    "            selected_individuals[individual_idx] = individual\n",
    "        \n",
    "        self.population = selected_individuals\n",
    "        \n",
    "        return fitness_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You'll want to add some more function nodes, and terminal nodes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_add = GPFunctionNode(arg_count=2, func_name=\"Add\", gp_function=lambda x, y: x+y)\n",
    "gp_sub = GPFunctionNode(arg_count=2, func_name=\"Sub\", gp_function=lambda x, y: x-y)\n",
    "\n",
    "gp_const1 = GPConstNode(-42)\n",
    "gp_const2 = GPConstNode(42)\n",
    "\n",
    "\n",
    "gp_func_set = [gp_add, gp_sub]\n",
    "gp_term_set = [gp_const1, gp_const2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is probably where most of your attention will go. \n",
    "You should connect a genetic program individual to your cart balancing task, and figure out a way to assign a `fitness` to each individual! \n",
    "\n",
    "I've given you a function that creates the simulation environment and randomly picks an action, like before. It also returns a value of `1` for a fitness, which you should also change. \n",
    "\n",
    "The selection function is also rather simplistic. It just picks the best individual in the population. You probably should implement something like tournament selection or at least fitness proportional selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evlauate_cartpole_gp(individual):\n",
    "    env = gym.make('CartPole-v0')\n",
    "    env._max_episode_steps = 500\n",
    "    observation = env.reset()\n",
    "    for step_num in range(1000):\n",
    "        \n",
    "        #This is what you want to change:\n",
    "        #Make your action the result of a genetic program evaluation!\n",
    "        action = random.choice([0,1])\n",
    "        \n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done: \n",
    "            break\n",
    "    env.close()\n",
    "    return 1\n",
    "\n",
    "\n",
    "def my_fitness_function(gp_individual):\n",
    "    return evlauate_cartpole_gp(gp_individual)\n",
    "\n",
    "def my_selection_function(gp_population):    \n",
    "    #pick max fitness individual\n",
    "    winner_index = np.argmax([i.fitness for i in gp_population])\n",
    "    return gp_population[winner_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once you've implemented the above functions, this code should work!\n",
    "### I also just picked some random values for the population size, max_depth, etc., but feel free to experiment with those as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fitnesses = []\n",
    "\n",
    "gp_pop = GPPopulation(pop_size=100, \n",
    "                      function_set=gp_func_set, \n",
    "                      terminal_set=gp_term_set,\n",
    "                      max_depth=6,\n",
    "                      prob_terminal=0.2)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    fitnesses = gp_pop.do_timestep(fitness_function=my_fitness_function, \n",
    "                   selection_function=my_selection_function,\n",
    "                   mutation_prob=0.1)\n",
    "    mean_fitnesses.append(np.mean(fitnesses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And to make sure things are progressing, let's plot the mean fitness over time!\n",
    "\n",
    "If your fitness function isn't working, you'll probably see a flat line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a69ae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(mean_fitnesses)\n",
    "pyplot.xlabel(\"Generations\")\n",
    "pyplot.ylabel(\"Fitness\")\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
